{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Analyze the dataset to understand its structure and features. It contains various attributes related to employee demographics, job roles, satisfaction levels, performance ratings, etc., along with a target variable indicating whether an employee has left the company (Yes or No).\n",
        "Perform preprocessing steps such as handling missing values, encoding categorical variables, and scaling numerical features if necessary.\n"
      ],
      "metadata": {
        "id": "_wFJ1J7E7GYT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import seaborn as sn\n",
        "import io"
      ],
      "metadata": {
        "id": "ros8NwpJ7NaY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "uploaded=files.upload()"
      ],
      "metadata": {
        "id": "OthbiUUz7gv3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df= pd.read_csv(io.BytesIO(uploaded['WA_Fn-UseC_-HR-Employee-Attrition (2).csv']))"
      ],
      "metadata": {
        "id": "nirR24sN7tJ_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "metadata": {
        "id": "Ietz4gWD74dP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "id": "MjSC3L-z8BXh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.isna().any()"
      ],
      "metadata": {
        "id": "5h0jdjmUPM08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.columns"
      ],
      "metadata": {
        "id": "_3cc0knVPS-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df['Attrition_ind'] = 0\n",
        "df.loc[df['Attrition'] =='Yes', 'Attrition_ind'] = 1"
      ],
      "metadata": {
        "id": "-kRVczeq9Kxi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "id": "_wOXHwbTGW_E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "continuous_columns = ['Age','DailyRate','DistanceFromHome', 'Education', 'EnvironmentSatisfaction','HourlyRate','JobInvolvement','JobLevel','JobSatisfaction', 'MonthlyIncome', 'MonthlyRate', 'NumCompaniesWorked','PercentSalaryHike',  'PerformanceRating', 'RelationshipSatisfaction','StockOptionLevel', 'TotalWorkingYears', 'TrainingTimesLastYear','WorkLifeBalance', 'YearsAtCompany', 'YearsInCurrentRole', 'YearsSinceLastPromotion','YearsWithCurrManager']\n",
        "data=df[continuous_columns]"
      ],
      "metadata": {
        "id": "PstSBrmo9RTT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.corrwith(df.Attrition_ind).plot.bar(figsize = (25, 10), title = \"Correlation with E Signed\", fontsize = 11, rot = 45, grid = True)"
      ],
      "metadata": {
        "id": "r_8_jOeH8T-5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Correlation Matrix\n",
        "sn.set(style=\"white\")\n",
        "\n",
        "# Compute the correlation matrix\n",
        "corr = data.corr()\n",
        "corr.head()"
      ],
      "metadata": {
        "id": "4FiO3MhaALBw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generate a mask for the upper triangle\n",
        "mask = np.zeros_like(corr, dtype=np.bool_)\n",
        "mask[np.triu_indices_from(mask)] = True\n",
        "\n",
        "# Set up the matplotlib figure\n",
        "f, ax = plt.subplots(figsize=(18, 15))\n",
        "\n",
        "# Generate a custom diverging colormap\n",
        "cmap = sn.diverging_palette(220, 10, as_cmap=True)\n",
        "\n",
        "# Draw the heatmap with the mask and correct aspect ratio\n",
        "sn.heatmap(corr, mask=mask, cmap='GnBu', vmax=.3, center=0,\n",
        "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})"
      ],
      "metadata": {
        "id": "OCRzeZf1Av5A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.get_dummies(df)\n",
        "df.columns"
      ],
      "metadata": {
        "id": "2urJMO91Fa6j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_main=df.drop(['EmployeeCount','EmployeeNumber','Over18_Y','StandardHours','Attrition_No', 'Attrition_Yes'],axis=1)\n",
        "data_main"
      ],
      "metadata": {
        "id": "D2SrMEbbFmwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_main['Attrition']=data_main['Attrition_ind']\n",
        "data_main"
      ],
      "metadata": {
        "id": "FzP7ITvkF3D_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_main=data_main.drop(['Attrition_ind'],axis=1)\n",
        "data_main.columns"
      ],
      "metadata": {
        "id": "c-v-NsMBGyrQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X=data_main.drop('Attrition',axis=1)\n",
        "y=data_main.Attrition"
      ],
      "metadata": {
        "id": "oCuAoqYPG3fh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "features_label = data_main.columns[:-1]"
      ],
      "metadata": {
        "id": "fpDqdM4EG6tR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting Random Forest Classification to the Training set\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(n_estimators = 200, criterion = 'entropy', random_state = 0)\n",
        "classifier.fit(X, y)\n",
        "importances = classifier.feature_importances_\n",
        "indices = np. argsort(importances)[::-1]\n",
        "for i in range(X.shape[1]):\n",
        "    print (\"%2d) %-*s %f\" % (i + 1, 30, features_label[i],importances[indices[i]]))"
      ],
      "metadata": {
        "id": "IulO9BIRG93B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title('Feature Importances')\n",
        "plt.bar(range(X.shape[1]),importances[indices], color=\"blue\", align=\"center\", width=100)\n",
        "plt.xticks(range(X.shape[1]),features_label, rotation=90)\n",
        "plt.xlim([-1, X.shape[1]])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "hqKXePLDHCWK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting into Train and Test Set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.2,random_state = 0)"
      ],
      "metadata": {
        "id": "n9xBOoh2HaW2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Feature Scaling\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "sc = StandardScaler()\n",
        "X_train2 = pd.DataFrame(sc.fit_transform(X_train))\n",
        "X_test2 = pd.DataFrame(sc.transform(X_test))\n",
        "X_train2.columns = X_train.columns.values\n",
        "X_test2.columns = X_test.columns.values\n",
        "X_train2.index = X_train.index.values\n",
        "X_test2.index = X_test.index.values\n",
        "X_train = X_train2\n",
        "X_test = X_test2"
      ],
      "metadata": {
        "id": "1KCCEyeFHh1G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## DecisionTree\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score, precision_score, recall_score\n",
        "classifier = DecisionTreeClassifier(criterion=\"gini\", max_depth=5,min_samples_split=2,  min_samples_leaf=1,random_state=42)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "results = pd.DataFrame([['DecisionTree', acc, prec, rec, f1]], columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "results"
      ],
      "metadata": {
        "id": "S4n7ceR-HmYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Randomforest\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "classifier = RandomForestClassifier(random_state = 0, n_estimators = 100, criterion = 'entropy')\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['Random Forest (n=100)', acc, prec, rec, f1]], columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "PixdW-GJHtto"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.concat([results, model_results], ignore_index = True)\n",
        "results"
      ],
      "metadata": {
        "id": "BO6bL7kbI6i0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#GradientBoostingRegressor\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "classifier = GradientBoostingClassifier( n_estimators=3000, learning_rate=0.05, max_depth=4, max_features='sqrt', min_samples_leaf=15, min_samples_split=10, random_state =5)\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['GradientBoostingclassifier (n=100)', acc, prec, rec, f1]], columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "Y7XDNUvTJba3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.concat([results, model_results], ignore_index = True)\n",
        "results"
      ],
      "metadata": {
        "id": "i9853yiAJrfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import xgboost as xgb\n",
        "classifier = xgb.XGBClassifier(max_depth=2, n_estimators=5000,\n",
        "learning_rate=0.05)\n",
        "\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['xgboost (n=100)', acc, prec, rec, f1]], columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "model_results"
      ],
      "metadata": {
        "id": "KJuyYuAaJ0sr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.concat([results, model_results], ignore_index = True)\n",
        "results"
      ],
      "metadata": {
        "id": "V4NHM3hSJdGV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## AdaBoostClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "classifier = AdaBoostClassifier(random_state = 0, n_estimators = 100,\n",
        "                                    )\n",
        "classifier.fit(X_train, y_train)\n",
        "\n",
        "# Predicting Test Set\n",
        "y_pred = classifier.predict(X_test)\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "prec = precision_score(y_test, y_pred)\n",
        "rec = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "model_results = pd.DataFrame([['AdaBoostClassifiet (n=100)', acc, prec, rec, f1]], columns = ['Model', 'Accuracy', 'Precision', 'Recall', 'F1 Score'])\n",
        "\n",
        "model_results"
      ],
      "metadata": {
        "id": "zR4loUAfKL2p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = pd.concat([results, model_results], ignore_index = True)\n",
        "results"
      ],
      "metadata": {
        "id": "P98uk4IcKReg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## EXTRA: Confusion Matrix\n",
        "cm = confusion_matrix(y_test, y_pred) # rows = truth, cols = prediction\n",
        "df_cm = pd.DataFrame(cm, index = (0, 1), columns = (0, 1))\n",
        "plt.figure(figsize = (10,7))\n",
        "sn.set(font_scale=1.4)\n",
        "sn.heatmap(df_cm, annot=True, fmt='g')\n",
        "print(\"Test Data Accuracy: %0.4f\" % accuracy_score(y_test, y_pred))"
      ],
      "metadata": {
        "id": "BFKbqprFKbuw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}